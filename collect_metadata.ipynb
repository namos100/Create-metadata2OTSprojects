{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a5e5d60c-c153-472c-b5ef-095f9fedd828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "718df5a6-dbb4-4e15-9957-d63370c464e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct GEO URL\n",
    "def construct_geo_url(geo_code):\n",
    "    geo_prefix = geo_code[:6]  # First 6 characters (e.g., GSE224)\n",
    "    file_name = f\"{geo_code}_family.soft\"\n",
    "    geo_url = f\"https://ftp.ncbi.nlm.nih.gov/geo/series/{geo_prefix}nnn/{geo_code}/soft/{file_name}.gz\"\n",
    "    return geo_url, file_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ab829-ee56-47a0-94df-2f111c82d7bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "aca9b832-3df0-4273-92da-b994795c0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_general_rows2csv(soft_file, head_l, row_number, samples_amount, output_csv):\n",
    "    \n",
    "    if head_l == \"^DATABASE\":\n",
    "        head_n = \"!Database\"\n",
    "    elif head_l == \"^SERIES\":\n",
    "        head_n = \"!Series\"\n",
    "    elif head_l == \"^PLATFORM\":\n",
    "        head_n = \"!Platform\"\n",
    "    else:\n",
    "        head_n = None  # or some default value\n",
    "        \n",
    "    with open(output_csv, 'a') as cf:\n",
    "        field_name = soft_file[row_number].split(\"=\")[0].strip()\n",
    "        field_name = field_name[1:]\n",
    "        value = soft_file[row_number].split(\"=\")[1].strip()\n",
    "        # Create the row: first the field name, then the value repeated `samples_amount` times\n",
    "        row = field_name + \"\\t\" + \"\\t\".join([value] * samples_amount) + \"\\n\"\n",
    "        cf.write(row)\n",
    "        #print(\"row:\\n\", row)\n",
    "        row_number += 1\n",
    "        while row_number < len(soft_file) and soft_file[row_number].startswith(head_n):\n",
    "            field_name = soft_file[row_number].split(\"=\")[0].strip()\n",
    "            field_name = field_name[1:]\n",
    "            if (field_name == \"Series_sample_id\"):\n",
    "                row_number += 1\n",
    "                continue\n",
    "            value = soft_file[row_number].split(\"=\")[1].strip()  \n",
    "            row = field_name + \"\\t\" + \"\\t\".join([value] * samples_amount)+\"\\n\"\n",
    "            #print(\"row:\\n\", row)\n",
    "            cf.write(row)\n",
    "            row_number += 1\n",
    "            \n",
    "    return row_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "952639d1-7a27-405c-a1ee-1a3b8e04c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_samples_rows2csv(soft_file, row_number, samples_amount, output_csv):\n",
    "    \n",
    "    samples_dict = {}\n",
    "    while row_number < len(soft_file) and (soft_file[row_number].startswith(\"!Sample\") or soft_file[row_number].startswith(\"^SAMPLE\")):\n",
    "    #while i < len(soft_file):\n",
    "        # Split the line at the first '=' and strip any surrounding whitespace\n",
    "        key, value = soft_file[row_number].split('=', 1)\n",
    "        key = key.strip()[1:]\n",
    "        value = value.strip()\n",
    "        \n",
    "        # Initialize the key in the dictionary if it doesn't exist\n",
    "        if key not in samples_dict:\n",
    "            samples_dict[key] = []\n",
    "            \n",
    "        if (len(samples_dict[\"SAMPLE\"]) == len(samples_dict[key])) and (len(samples_dict[\"SAMPLE\"]) > 0) and (key != \"SAMPLE\"):\n",
    "            #print (samples_dict)\n",
    "            samples_dict[key][-1] = samples_dict[key][-1] + \",, \" + value\n",
    "        else:\n",
    "            # Add the value to the list corresponding to the key\n",
    "            samples_dict[key].append(value)\n",
    "        \n",
    "        # Move to the next line\n",
    "        row_number += 1\n",
    "    \n",
    "    with open(output_csv, 'a', newline='') as csvfile:\n",
    "        # Create a CSV writer with tab delimiter\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "\n",
    "        # Write each key and its corresponding values as a row\n",
    "        for key, values in samples_dict.items():\n",
    "            # Create a row with the key and its values\n",
    "            row = [key] + values\n",
    "            csvwriter.writerow(row)  \n",
    "    return row_number\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "268fe6ce-5e8e-47c3-9049-288de579acd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transpose_csv(csv_file):\n",
    "    # Read the CSV file\n",
    "    table = pd.read_csv(csv_file, sep = \"\\t\")\n",
    "    #print(\"Table:\\n\",table)\n",
    "    \n",
    "    table_t = np.transpose(table)\n",
    "    #print(\"Table_T:\\n\",table_t)\n",
    "    \n",
    "    # Write the transposed data to a new CSV file\n",
    "    table_t.to_csv(csv_file, sep = \"\\t\", header = True, index = False)\n",
    "    \n",
    "#default_input_file = \"all_GSE224028_samples.csv\"\n",
    "#transpose_csv(default_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7af345c6-c990-446a-ac2d-3d574082a36f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE205589\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE205nnn/GSE205589/soft/GSE205589_family.soft.gz\n",
      "\n",
      "Samples_amount 23 \n",
      "______________________________\n",
      "GSE213486\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE213nnn/GSE213486/soft/GSE213486_family.soft.gz\n",
      "\n",
      "Samples_amount 9 \n",
      "______________________________\n",
      "GSE114724\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE114nnn/GSE114724/soft/GSE114724_family.soft.gz\n",
      "\n",
      "Samples_amount 10 \n",
      "______________________________\n",
      "GSE162086\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE162nnn/GSE162086/soft/GSE162086_family.soft.gz\n",
      "\n",
      "Samples_amount 40 \n",
      "______________________________\n",
      "GSE230227\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE230nnn/GSE230227/soft/GSE230227_family.soft.gz\n",
      "\n",
      "Samples_amount 33 \n",
      "______________________________\n",
      "GSE121637\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE121nnn/GSE121637/soft/GSE121637_family.soft.gz\n",
      "\n",
      "Samples_amount 6 \n",
      "______________________________\n",
      "GSE176201\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE176nnn/GSE176201/soft/GSE176201_family.soft.gz\n",
      "\n",
      "Samples_amount 14 \n",
      "______________________________\n",
      "GSE187515\n",
      "Downloading https://ftp.ncbi.nlm.nih.gov/geo/series/GSE187nnn/GSE187515/soft/GSE187515_family.soft.gz\n",
      "\n",
      "Samples_amount 104 \n",
      "______________________________\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-e7d004ddfcbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgeo_code\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"Null\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0msamples_amount_inOTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# Construct the GEO URL and file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mgeo_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_geo_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if glob.glob(\"*.soft\"):\n",
    "        !rm *.soft\n",
    "    \n",
    "    # Set default input file path\n",
    "    default_input_file = \"/home/bcrlab/igguest/home/bcrlab/igguest/naama/OTS_Datasets/copy_output_ProjectsCodesAndCounts.txt\"\n",
    "    #input_file = sys.argv[1] if len(sys.argv) > 1 else default_input_file\n",
    "    input_file = default_input_file #input()\n",
    "    \n",
    "    # Read the input file, skipping the header\n",
    "    with open(input_file, 'r') as infile:\n",
    "        next(infile)  # Skip the header line\n",
    "        for line in infile:\n",
    "            # Extract the GEO code from the 3rd column\n",
    "            columns = line.strip().split()\n",
    "            geo_code = columns[2] if len(columns) > 1 else None\n",
    "            \n",
    "            if (geo_code!=\"Null\"):\n",
    "                print(geo_code)\n",
    "                samples_amount_inOTS = columns[3]\n",
    "                # Construct the GEO URL and file name\n",
    "                geo_url, file_name = construct_geo_url(geo_code)\n",
    "                print(f\"Downloading {geo_url}\")\n",
    "\n",
    "                # Download the file\n",
    "                subprocess.run([\"wget\", geo_url], check=True)\n",
    "\n",
    "                # Decompress the file\n",
    "                subprocess.run([\"gunzip\", f\"{file_name}.gz\"], check=True)\n",
    "\n",
    "                # Output CSV file\n",
    "                output_csv = f\"{geo_code}_collected_metadata.csv\"\n",
    "\n",
    "                # Initialize the CSV header\n",
    "                with open(output_csv, 'w') as csvfile:\n",
    "                    soft_file_open = open(file_name , 'r')\n",
    "                    soft_file = soft_file_open.readlines()\n",
    "                    \n",
    "                    samples_amount =  sum(line.count('^SAMPLE') for line in soft_file)\n",
    "                    print(\"\\nSamples_amount\",samples_amount, \"\\n______________________________\")\n",
    "                    row_number = 0\n",
    "                    while (row_number < len(soft_file)):\n",
    "                        line = soft_file[row_number]\n",
    "                        head_l = line.split(\"=\")[0].strip()\n",
    "                        #print(head_l)\n",
    "                        if ((head_l == \"^DATABASE\") | (head_l == \"^SERIES\") | (head_l == \"^PLATFORM\") ):\n",
    "                            #print(\"IF RECOGNIZE \",head_l)\n",
    "                            row_number = add_general_rows2csv(soft_file, head_l,row_number, samples_amount, output_csv)\n",
    "                            \n",
    "                        elif (head_l ==\"^SAMPLE\"):\n",
    "                            #print(\"IF RECOGNIZE \",head_l)\n",
    "                            row_number = add_samples_rows2csv(soft_file,row_number, samples_amount, output_csv)\n",
    "\n",
    "                        else:\n",
    "                            print(\"The follow line is an unknown line in the soft file:\\n\", soft_file[row_number])\n",
    "                            row_number+=1        \n",
    "                \n",
    "                    transpose_csv(output_csv)\n",
    "                    os.remove(file_name)\n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d3b80ec8-5e18-4d3a-9d0e-456352ace3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae387381-8119-451c-819a-7e319e4f7152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
